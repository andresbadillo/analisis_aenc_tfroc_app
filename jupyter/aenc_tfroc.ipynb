{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute from VSCode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ShareplumRequestError",
          "evalue": "Shareplum HTTP Post Failed : 403 Client Error: Forbidden for url: https://ruitoqueesp1.sharepoint.com/_forms/default.aspx?wa=wsignin1.0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\rbadillo\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shareplum\\request_helper.py:17\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(session, url, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mpost(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 17\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[1;32mc:\\Users\\rbadillo\\AppData\\Local\\anaconda3\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://ruitoqueesp1.sharepoint.com/_forms/default.aspx?wa=wsignin1.0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mShareplumRequestError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 195\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl proceso ha finalizado exitosamente.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Ejecutar la funci칩n autom치ticamente\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m procesar_archivos()\n",
            "Cell \u001b[1;32mIn[1], line 67\u001b[0m, in \u001b[0;36mprocesar_archivos\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m sharepoint_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentos Compartidos/aenc/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmes\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Conectarse a SharePoint\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m site \u001b[38;5;241m=\u001b[39m conectar_sharepoint(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password)\n\u001b[0;32m     68\u001b[0m folder \u001b[38;5;241m=\u001b[39m site\u001b[38;5;241m.\u001b[39mFolder(sharepoint_folder)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Cargar archivos \"aenc\" y \"tfroc\" desde SharePoint\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[1], line 46\u001b[0m, in \u001b[0;36mconectar_sharepoint\u001b[1;34m(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconectar_sharepoint\u001b[39m(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password):\n\u001b[1;32m---> 46\u001b[0m     authcookie \u001b[38;5;241m=\u001b[39m Office365(sharepoint_url, username\u001b[38;5;241m=\u001b[39msharepoint_user, password\u001b[38;5;241m=\u001b[39msharepoint_password)\u001b[38;5;241m.\u001b[39mGetCookies()\n\u001b[0;32m     47\u001b[0m     site \u001b[38;5;241m=\u001b[39m Site(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msharepoint_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sites/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msharepoint_site\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, authcookie\u001b[38;5;241m=\u001b[39mauthcookie, version\u001b[38;5;241m=\u001b[39mVersion\u001b[38;5;241m.\u001b[39mv365)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m site\n",
            "File \u001b[1;32mc:\\Users\\rbadillo\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shareplum\\office365.py:90\u001b[0m, in \u001b[0;36mOffice365.get_cookies\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m sectoken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_security_token(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musername, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword)\n\u001b[0;32m     89\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_point_site \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/_forms/default.aspx?wa=wsignin1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 90\u001b[0m response \u001b[38;5;241m=\u001b[39m post(requests, url, data\u001b[38;5;241m=\u001b[39msectoken)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcookies\n",
            "File \u001b[1;32mc:\\Users\\rbadillo\\AppData\\Local\\anaconda3\\Lib\\site-packages\\shareplum\\request_helper.py:20\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(session, url, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ShareplumRequestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShareplum HTTP Post Failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, err)\n",
            "\u001b[1;31mShareplumRequestError\u001b[0m: Shareplum HTTP Post Failed : 403 Client Error: Forbidden for url: https://ruitoqueesp1.sharepoint.com/_forms/default.aspx?wa=wsignin1.0"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import holidays_co\n",
        "import io\n",
        "from shareplum import Site\n",
        "from shareplum import Office365\n",
        "from shareplum.site import Version\n",
        "from pathlib import Path\n",
        "\n",
        "# Configurar el a침o y mes manualmente si es necesario\n",
        "anio = None  # Cambiar este valor al a침o deseado\n",
        "mes = None   # Cambiar este valor al mes deseado\n",
        "\n",
        "# Configurar el a침o y mes (puede cambiarse manualmente. si se deja None, tomar치 el a침o y mes actual)\n",
        "anio = datetime.now().year if anio is None else anio\n",
        "mes = datetime.now().month if mes is None else mes\n",
        "\n",
        "# Funci칩n para obtener el nombre del d칤a en espa침ol\n",
        "def obtener_dia_semana(fecha):\n",
        "    dias_semana = [\"Lunes\", \"Martes\", \"Mi칠rcoles\", \"Jueves\", \"Viernes\", \"S치bado\", \"Domingo\"]\n",
        "    dia_semana = datetime.strptime(fecha, \"%d-%m-%Y\").weekday()\n",
        "    return dias_semana[dia_semana]\n",
        "\n",
        "# Funci칩n para determinar el tipo de d칤a\n",
        "def tipo_dia(fecha):\n",
        "    fecha_obj = datetime.strptime(fecha, \"%d-%m-%Y\").date()\n",
        "    if holidays_co.is_holiday_date(fecha_obj):  # Verificar si es festivo\n",
        "        return \"Festivo\"\n",
        "    dia_semana = fecha_obj.weekday()  # 0: Lunes, 1: Martes, ..., 6: Domingo\n",
        "    return [\"H치bil\", \"H치bil\", \"H치bil\", \"H치bil\", \"H치bil\", \"S치bado\", \"Domingo\"][dia_semana]\n",
        "\n",
        "# Funci칩n para mapear el NT por rangos\n",
        "def mapear_nt_por_rango(valor):\n",
        "    if valor in {1, 2}:  # Comprobamos si el valor es exactamente 1 o 2\n",
        "        return valor\n",
        "    elif valor < 1:\n",
        "        return 1\n",
        "    elif valor < 30:\n",
        "        return 2\n",
        "    elif valor < 57.5:\n",
        "        return 3\n",
        "    return None  # O un valor por defecto si no encaja en ning칰n rango\n",
        "\n",
        "# Funci칩n para conectarse a SharePoint\n",
        "def conectar_sharepoint(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password):\n",
        "    authcookie = Office365(sharepoint_url, username=sharepoint_user, password=sharepoint_password).GetCookies()\n",
        "    site = Site(f\"{sharepoint_url}/sites/{sharepoint_site}\", authcookie=authcookie, version=Version.v365)\n",
        "    return site\n",
        "\n",
        "# Funci칩n para cargar archivos desde SharePoint\n",
        "def cargar_archivos_desde_sharepoint(folder, valid_extensions):\n",
        "    files = folder.files\n",
        "    aenc_files = [file for file in files if 'aenc' in file['Name'] and file['Name'].endswith(valid_extensions)]\n",
        "    tfroc_files = [file for file in files if 'tfroc' in file['Name'] and file['Name'].endswith(valid_extensions)]\n",
        "    return aenc_files, tfroc_files\n",
        "\n",
        "# Funci칩n para procesar los archivos\n",
        "def procesar_archivos():\n",
        "    # 游댳 DATOS DE SHAREPOINT\n",
        "    sharepoint_url = \"https://ruitoqueesp1.sharepoint.com\"\n",
        "    sharepoint_site = \"fronterascomerciales\"  # Nombre del sitio en SharePoint\n",
        "    sharepoint_user = \"rbadillo@ruitoqueesp.com\"\n",
        "    sharepoint_password = \"r2083502R\"\n",
        "    sharepoint_folder = f\"Documentos Compartidos/aenc/{anio}/{mes:02d}\"\n",
        "\n",
        "    # Conectarse a SharePoint\n",
        "    site = conectar_sharepoint(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password)\n",
        "    folder = site.Folder(sharepoint_folder)\n",
        "\n",
        "    # Cargar archivos \"aenc\" y \"tfroc\" desde SharePoint\n",
        "    valid_extensions = ('.TxF', '.TxR', '.Tx2')\n",
        "    aenc_files, tfroc_files = cargar_archivos_desde_sharepoint(folder, valid_extensions)\n",
        "\n",
        "    # Contar la cantidad de archivos \"aenc\" y \"tfroc\"\n",
        "    num_aenc_files = len(aenc_files)\n",
        "    num_tfroc_files = len(tfroc_files)\n",
        "    print(f\"Cantidad de archivos 'aenc' cargados: {num_aenc_files}\")\n",
        "    print(f\"Cantidad de archivos 'tfroc' cargados: {num_tfroc_files}\")\n",
        "\n",
        "    # Asegurarse de que la cantidad de archivos \"aenc\" sea igual a la cantidad de archivos \"tfroc\"\n",
        "    if num_aenc_files != num_tfroc_files:\n",
        "        print(\"La cantidad de archivos 'aenc' no es igual a la cantidad de archivos 'tfroc'. El proceso no puede continuar.\")\n",
        "        return\n",
        "\n",
        "    # Inicializar dataframes vac칤os para consolidar los resultados\n",
        "    consolidated_aenc_df = pd.DataFrame()\n",
        "    consolidated_df = pd.DataFrame()\n",
        "\n",
        "    # Diccionario de mapeo para la columna \"OR\"\n",
        "    mapeo_or = {\n",
        "        \"CUNM\": \"ENEL\",\n",
        "        \"SOLM\": \"AIRE\",\n",
        "        \"SANM\": \"ESSA\",\n",
        "        \"MARM\": \"AFINIA\",\n",
        "        \"NSAM\": \"ESSA\",\n",
        "        \"BOYM\": \"EBSA\",\n",
        "        \"CASM\": \"ENERCA\",\n",
        "        \"METM\": \"EMSA\",\n",
        "        \"QUIM\": \"EDEQ\",\n",
        "        \"RUIM\": \"RUITOQUE\",\n",
        "        \"CHOM\": \"DISPAC\",\n",
        "        \"CLOM\": \"EMCALI\"\n",
        "    }\n",
        "\n",
        "    # Procesar archivos d칤a a d칤a\n",
        "    for aenc_file in aenc_files:\n",
        "        aenc_file_name = aenc_file['Name']\n",
        "        aenc_file_content = folder.get_file(aenc_file_name)\n",
        "        # Extraer el d칤a y el mes del nombre del archivo\n",
        "        day = Path(aenc_file_name).stem[-4:]  # Los 칰ltimos 4 caracteres son el d칤a\n",
        "        date = f\"{day[2:]}-{day[:2]}-{anio}\"  # Formatear como dd-mm-aaaa\n",
        "\n",
        "        # Buscar el archivo tfroc correspondiente\n",
        "        tfroc_file = next((f for f in tfroc_files if day in f['Name']), None)\n",
        "        if tfroc_file is None:\n",
        "            print(f\"No se encontr칩 un archivo tfroc correspondiente para el d칤a {day}.\")\n",
        "            continue\n",
        "\n",
        "        tfroc_file_content = folder.get_file(tfroc_file['Name'])\n",
        "\n",
        "        # Leer los archivos con el separador \";\"\n",
        "        aenc_df = pd.read_csv(io.BytesIO(aenc_file_content), sep=\";\", encoding='latin1')\n",
        "        tfroc_df = pd.read_csv(io.BytesIO(tfroc_file_content), sep=\";\", encoding='latin1')\n",
        "\n",
        "        # Renombrar columnas para facilitar la uni칩n\n",
        "        aenc_df.rename(columns={\"CODIGO SIC\": \"CODIGO FRONTERA\"}, inplace=True)\n",
        "\n",
        "        # Agregar columnas adicionales al dataframe de aenc\n",
        "        horas = [col for col in aenc_df.columns if \"HORA\" in col]\n",
        "        aenc_df.insert(0, \"FECHA\", date)\n",
        "        aenc_df.insert(1, \"DIA\", obtener_dia_semana(date))\n",
        "        aenc_df.insert(2, \"TIPO_DIA\", tipo_dia(date))\n",
        "        aenc_df[\"TOTAL CONSUMO\"] = aenc_df.loc[:, horas].sum(axis=1)\n",
        "\n",
        "        # Consolidar los datos de aenc\n",
        "        consolidated_aenc_df = pd.concat([consolidated_aenc_df, aenc_df], ignore_index=True)\n",
        "\n",
        "        # Unir los dos dataframes utilizando \"CODIGO FRONTERA\"\n",
        "        merged_df = pd.merge(aenc_df, tfroc_df[[\"CODIGO FRONTERA\", \"FACTOR DE PERDIDAS\", \"MERCADO COMERCIALIZACI칍N QUE EXPORTA\", \"NIVEL DE TENSION\"]], on=\"CODIGO FRONTERA\", how=\"inner\")\n",
        "\n",
        "        # Dividir los valores de consumo horario por el FACTOR DE PERDIDAS\n",
        "        for hora in horas:\n",
        "            merged_df[hora] = merged_df[hora] / merged_df[\"FACTOR DE PERDIDAS\"]\n",
        "\n",
        "        # Agregar columnas adicionales al archivo de salida\n",
        "        merged_df.rename(columns={\"CODIGO PROPIO\": \"NOMBRE FRONTERA\"}, inplace=True)\n",
        "        daily_df = merged_df.loc[:, [\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\", \"MERCADO COMERCIALIZACI칍N QUE EXPORTA\", \"NIVEL DE TENSION\",\"TIPO DE AGRUPACI칍N\", \"IMPO - EXPO\"] + horas]\n",
        "\n",
        "        # Agregar columna de fecha, d칤a y tipo de d칤a\n",
        "        daily_df.insert(0, \"FECHA\", date)\n",
        "        daily_df.insert(1, \"DIA\", obtener_dia_semana(date))\n",
        "        daily_df.insert(2, \"TIPO_DIA\", tipo_dia(date))\n",
        "\n",
        "        # Agregar columna \"OR\" basada en el mapeo\n",
        "        daily_df.insert(6, \"OR\", daily_df[\"MERCADO COMERCIALIZACI칍N QUE EXPORTA\"].map(mapeo_or))\n",
        "\n",
        "        # Agregar columna \"NT\" basada en la funci칩n de mapeo por rangos\n",
        "        daily_df.insert(8, \"NT\", daily_df[\"NIVEL DE TENSION\"].map(mapear_nt_por_rango))\n",
        "\n",
        "        # Agregar columna de total de consumo por frontera\n",
        "        daily_df[\"TOTAL CONSUMO\"] = daily_df.loc[:, horas].sum(axis=1)\n",
        "\n",
        "        # Agregar los resultados al dataframe consolidado\n",
        "        consolidated_df = pd.concat([consolidated_df, daily_df], ignore_index=True)\n",
        "        \n",
        "    # Ordenar los DataFrames por las columnas \"FECHA\" y \"CODIGO FRONTERA\"\n",
        "    consolidated_aenc_df = consolidated_aenc_df.sort_values(by=[\"FECHA\", \"CODIGO FRONTERA\"])\n",
        "    consolidated_df = consolidated_df.sort_values(by=[\"FECHA\", \"CODIGO FRONTERA\"])\n",
        "\n",
        "    # Convertir los dataframes a CSV en memoria y subir a SharePoint\n",
        "    output_aenc_file_name = f\"aenc_consolidado_{mes:02d}_{anio}.csv\"\n",
        "    output_file_name = f\"consumos_{mes:02d}_{anio}.csv\"\n",
        "    output_total_file_name = f\"total_consumo_{mes:02d}_{anio}.csv\"\n",
        "\n",
        "    # Subir el archivo de aenc consolidado a SharePoint\n",
        "    aenc_csv = consolidated_aenc_df.to_csv(index=False, sep=\",\", encoding='utf-8-sig')\n",
        "    folder.upload_file(aenc_csv.encode('utf-8-sig'), output_aenc_file_name)\n",
        "    print(f\"Archivo subido a SharePoint: {output_aenc_file_name}\")\n",
        "\n",
        "    # Subir el archivo de consumos consolidado a SharePoint\n",
        "    consumos_csv = consolidated_df.to_csv(index=False, sep=\",\", encoding='utf-8-sig')\n",
        "    folder.upload_file(consumos_csv.encode('utf-8-sig'), output_file_name)\n",
        "    print(f\"Archivo subido a SharePoint: {output_file_name}\")\n",
        "\n",
        "    # Generar y subir el archivo consolidado total de consumo por frontera a SharePoint\n",
        "    consolidated_total_df = consolidated_df.groupby([\"CODIGO FRONTERA\", \"NOMBRE FRONTERA\",\"TIPO DE AGRUPACI칍N\", \"IMPO - EXPO\"], as_index=False).agg({\"TOTAL CONSUMO\": \"sum\"})\n",
        "    total_consumo_csv = consolidated_total_df.to_csv(index=False, sep=\",\", encoding='utf-8-sig')\n",
        "    folder.upload_file(total_consumo_csv.encode('utf-8-sig'), output_total_file_name)\n",
        "    print(f\"Archivo subido a SharePoint: {output_total_file_name}\")\n",
        "\n",
        "    # Mensaje de confirmaci칩n al finalizar el proceso\n",
        "    print(\"El proceso ha finalizado exitosamente.\")\n",
        "\n",
        "# Ejecutar la funci칩n autom치ticamente\n",
        "procesar_archivos()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actualizar `consumos_{anio}` en la carpeta *fact_consumos*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando archivo 'consumos_2025.csv' desde SharePoint...\n",
            "Archivo 'consumos_2025.csv' cargado exitosamente.\n",
            "Cargando archivo 'consumos_08_2025.csv' desde SharePoint...\n",
            "Archivo 'consumos_08_2025.csv' cargado exitosamente.\n",
            "Concatenando los datos...\n",
            "Concatenaci칩n completada.\n",
            "Preparando para guardar y subir 'consumos_2025.csv'...\n",
            "Archivo guardado en: archivos_descargados\\consumos_2025.csv\n",
            "Subiendo 'consumos_2025.csv' a SharePoint...\n",
            "Error al subir 'consumos_2025.csv': Shareplum HTTP Post Failed : ('Connection aborted.', TimeoutError('The write operation timed out'))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from shareplum import Office365, Site\n",
        "from shareplum.site import Version\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Configurar el a침o y mes manualmente si es necesario\n",
        "anio = None  # Cambiar este valor al a침o deseado\n",
        "mes = None   # Cambiar este valor al mes deseado\n",
        "\n",
        "# Configurar el a침o y mes (puede cambiarse manualmente. si se deja None, tomar치 el a침o y mes actual)\n",
        "anio = datetime.now().year if anio is None else anio\n",
        "mes = datetime.now().month if mes is None else mes\n",
        "\n",
        "# Nombres de los archivos\n",
        "output_file_name = f\"consumos_{mes:02d}_{anio}.csv\"\n",
        "consumos_anio_file_name = f\"consumos_{anio}.csv\"\n",
        "\n",
        "def conectar_sharepoint(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password):\n",
        "    \"\"\"Funci칩n para conectarse a SharePoint\"\"\"\n",
        "    authcookie = Office365(sharepoint_url, username=sharepoint_user, password=sharepoint_password).GetCookies()\n",
        "    site = Site(f\"{sharepoint_url}/sites/{sharepoint_site}\", authcookie=authcookie, version=Version.v365)\n",
        "    return site\n",
        "\n",
        "def cargar_archivo_desde_sharepoint(folder, file_name):\n",
        "    \"\"\"Funci칩n para cargar archivos desde SharePoint\"\"\"\n",
        "    print(f\"Cargando archivo '{file_name}' desde SharePoint...\")\n",
        "    file_content = folder.get_file(file_name)\n",
        "    df = pd.read_csv(io.BytesIO(file_content), sep=\",\", encoding='utf-8-sig')\n",
        "    print(f\"Archivo '{file_name}' cargado exitosamente.\")\n",
        "    return df\n",
        "\n",
        "def subir_archivo_a_sharepoint(folder, file_name, df):\n",
        "    \"\"\"Funci칩n para guardar localmente y subir a SharePoint sin l칤neas vac칤as\"\"\"\n",
        "    print(f\"Preparando para guardar y subir '{file_name}'...\")\n",
        "    # Crear carpeta local si no existe\n",
        "    os.makedirs(\"archivos_descargados\", exist_ok=True)\n",
        "\n",
        "    # 1) Eliminar filas completamente vac칤as\n",
        "    df_clean = df.dropna(how=\"all\")\n",
        "\n",
        "    # 2) Guardar CSV local sin l칤neas vac칤as adicionales\n",
        "    local_path = os.path.join(\"archivos_descargados\", file_name)\n",
        "    with open(local_path, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "        # Escribir con configuraci칩n que evita l칤neas en blanco extra\n",
        "        df_clean.to_csv(f, index=False, sep=\",\", encoding=\"utf-8-sig\")\n",
        "    print(f\"Archivo guardado en: {local_path}\")\n",
        "\n",
        "    # 3) Leer binario y subir a SharePoint\n",
        "    try:\n",
        "        with open(local_path, \"rb\") as fbin:\n",
        "            file_bytes = fbin.read()\n",
        "        print(f\"Subiendo '{file_name}' a SharePoint...\")\n",
        "        folder.upload_file(file_bytes, file_name)\n",
        "        print(f\"Archivo '{file_name}' subido exitosamente.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al subir '{file_name}': {e}\")\n",
        "\n",
        "def procesar_archivos(anio, mes, sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password):\n",
        "    \"\"\"Funci칩n principal para procesar los archivos\"\"\"\n",
        "    site = conectar_sharepoint(sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password)\n",
        "\n",
        "    # Ruta del SharePoint para el archivo \"consumos_{anio}.csv\"\n",
        "    sharepoint_folder_anio = f\"Documentos Compartidos/aenc/fact_consumos\"\n",
        "    folder_anio = site.Folder(sharepoint_folder_anio)\n",
        "\n",
        "    # Ruta del SharePoint para el archivo \"consumos_{mes:02d}_{anio}.csv\"\n",
        "    sharepoint_folder_mes = f\"Documentos Compartidos/aenc/{anio}/{mes:02d}\"\n",
        "    folder_mes = site.Folder(sharepoint_folder_mes)\n",
        "\n",
        "    # Cargar los archivos desde SharePoint\n",
        "    consumos_anio_df = cargar_archivo_desde_sharepoint(folder_anio, consumos_anio_file_name)\n",
        "    consumos_mes_df = cargar_archivo_desde_sharepoint(folder_mes, output_file_name)\n",
        "\n",
        "    # Convertir la columna \"FECHA\" a datetime para facilitar el filtrado\n",
        "    consumos_anio_df['FECHA'] = pd.to_datetime(consumos_anio_df['FECHA'], format='%Y-%m-%d')\n",
        "    consumos_mes_df['FECHA'] = pd.to_datetime(consumos_mes_df['FECHA'], format='%d-%m-%Y')\n",
        "\n",
        "    # Filtrar los datos del mes actual en el archivo \"consumos_{anio}.csv\"\n",
        "    consumos_anio_df = consumos_anio_df[~((consumos_anio_df['FECHA'].dt.year == anio) & (consumos_anio_df['FECHA'].dt.month == mes))]\n",
        "\n",
        "    # Concatenar los datos del archivo \"consumos_{mes:02d}_{anio}.csv\" con el archivo \"consumos_{anio}.csv\"\n",
        "    print(\"Concatenando los datos...\")\n",
        "    consumos_actualizado_df = pd.concat([consumos_anio_df, consumos_mes_df], ignore_index=True)\n",
        "    print(\"Concatenaci칩n completada.\")\n",
        "\n",
        "    # Ordenar el DataFrame resultante por las columnas \"FECHA\" y \"CODIGO FRONTERA\"\n",
        "    consumos_actualizado_df = consumos_actualizado_df.sort_values(by=[\"FECHA\", \"CODIGO FRONTERA\"])\n",
        "\n",
        "    # Guardar el DataFrame resultante de nuevo en \"consumos_{anio}.csv\"\n",
        "    subir_archivo_a_sharepoint(folder_anio, consumos_anio_file_name, consumos_actualizado_df)\n",
        "\n",
        "# Datos de SharePoint\n",
        "sharepoint_url = \"https://ruitoqueesp1.sharepoint.com\"\n",
        "sharepoint_site = \"fronterascomerciales\"  # Nombre del sitio en SharePoint\n",
        "sharepoint_user = \"rbadillo@ruitoqueesp.com\"\n",
        "sharepoint_password = \"r2083502R\"\n",
        "\n",
        "# Ejecutar la funci칩n principal\n",
        "procesar_archivos(anio, mes, sharepoint_url, sharepoint_site, sharepoint_user, sharepoint_password)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s96LngwlcxB"
      },
      "source": [
        "## Borrar la carpeta `content`\n",
        "\n",
        "Ejecuta el siguiente c칩digo para borrar rapidamente la carpeta \"content\" y todos sus archivos temporales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9a1a_f4k4Dq",
        "outputId": "d03f2a4d-a4e7-4844-b91a-6bb28716debf"
      },
      "outputs": [],
      "source": [
        "# Ruta de la carpeta predeterminada en Google Colab\n",
        "folder_path = '/content'\n",
        "\n",
        "# Eliminar todos los archivos en la carpeta\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "print(\"\\nTodos los archivos cargados han sido eliminados de la carpeta content de Google Colab.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_WF4iWrT-HqO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
